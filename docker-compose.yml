services:
  postgres:
    image: postgres:latest
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: "${POSTGRES_PASSWORD}"
      POSTGRES_USER: "${POSTGRES_USER}"
      POSTGRES_DB: "${POSTGRES_DB}"
    command: ["postgres", "-c", "wal_level=logical"]
    restart: unless-stopped

  zookeeper:
    image: confluentinc/cp-zookeeper:5.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.5.3
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

  debezium:
    image: debezium/connect:1.4
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      STATUS_STORAGE_TOPIC: my_connect_statuses
      KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    depends_on: [kafka, postgres, schema-registry]
    ports:
      - 8083:8083

  debezium-connector-setup:
    image: curlimages/curl:latest
    depends_on:
      - debezium
    volumes:
      - ./debezium:/app
    working_dir: /app
    command: sh -c "chmod +x db_connect.sh && ./db_connect.sh"
    restart: "no"

  schema-registry:
    image: confluentinc/cp-schema-registry:5.5.3
    environment:
      - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=zookeeper:2181
      - SCHEMA_REGISTRY_HOST_NAME=schema-registry
      - SCHEMA_REGISTRY_LISTENERS=http://schema-registry:8081,http://localhost:8081
    ports:
      - 8081:8081
    depends_on: [zookeeper, kafka]
  
  kafka-manager:
    image: hlebalbau/kafka-manager:stable
    restart: always
    ports:
      - "9002:9000"
    depends_on:
      - zookeeper
      - kafka
    environment:
      ZK_HOSTS: "zookeeper:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null

  minio:
    image: minio/minio:RELEASE.2024-04-18T19-09-19Z
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./minio-data:/data
    environment:
      MINIO_ROOT_USER: "${MINIO_USER}"
      MINIO_ROOT_PASSWORD: "${MINIO_PASSWORD}"
    command: server --console-address ":9001" /data
    restart: unless-stopped

  minio-init:
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      chmod +x /usr/bin/mc;
      /usr/bin/mc alias set myminio http://minio:9000 ${MINIO_USER} ${MINIO_PASSWORD};
      /usr/bin/mc mb myminio/streamed-data;
      exit 0;
      "

  spark:
    image: bitnami/spark:3.5.0
    container_name: spark
    depends_on:
      - kafka
      - schema-registry
      - minio-init
    ports:
      - "4040:4040"
    command:
      - "/opt/bitnami/spark/bin/spark-submit"
      - "--packages"
      - "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-avro_2.12:3.5.0,io.delta:delta-spark_2.12:3.0.0,org.apache.hadoop:hadoop-aws:3.3.4"
      - "--conf=spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension"
      - "--conf=spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog"
      - "--conf=spark.hadoop.fs.s3a.access.key=${MINIO_USER}"
      - "--conf=spark.hadoop.fs.s3a.secret.key=${MINIO_PASSWORD}"
      - "--conf=spark.hadoop.fs.s3a.endpoint=http://minio:9000"
      - "--conf=spark.hadoop.fs.s3a.path.style.access=true"
      - "/opt/spark-jobs/kafka-to-minio-job.py"
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_UI_PORT: "4040"
      PIP_PACKAGES: confluent-kafka==2.10.0
    volumes:
      - ./spark-jobs:/opt/spark-jobs
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  minio_data:
    driver: local
